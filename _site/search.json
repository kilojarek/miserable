[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "Education is the path from cocky ignorance to miserable uncertainty\nMark Twain (allegedly)"
  },
  {
    "objectID": "posts/R with a little help from a few friends/index.html",
    "href": "posts/R with a little help from a few friends/index.html",
    "title": "R, with a little help from a few friends",
    "section": "",
    "text": "My presentation at the Northern BUG\nIn January 2023 I gave a short talk at the 8th meeting of the Northern Bioinformatics User Group (nBUG for short), an informal network of computational biologists and users or bioinformatics services in the (loosely defined) north of England. If you haven’t heard about us and are in range of a reasonable commute, please come to one of our next meetings (we have three one-day, single-track meetings per year), it’s really nice :-).\nMy talk wasn’t actually that short, as I ran over time and could not finish it properly. My excuse is that I was juggling a presentation (with slides), a live demo in R Studio and sharing my screen over Teams, over a single projector. This makes it a very good reason to write my short presentation as a blog post.\n\n\nWho may find this useful?\nWhen I thought about the target audience of the talk, I had in mind postgraduate students, who had already done some work in R and are familiar with the basics of the language (e.g. various data types, loading and transforming data, working in R Studio), but who may not have thought about how to organise their data and scripts, or be aware of really simple tricks that would make their work much more effective and efficient. I didn’t really know whether this was the right pitch, but a few post-talk comments indicated that it was a good one.\n\n\n\nHe’s not wrong ;-). Photo by Andy Mason.\n\n\n\n\n1. Use projects + here + Rmd/qmd for everything\nThis advice is number one for a reason - projects will instantly make your work easier, because they will force you to organise your files into a consistent structure. And if you combine it with the package here, you will get extra benefits of making your code simpler and, most importantly, portable.\nI usually set up a self-explanatory three-folder structure within any project: folders code, data, and output. You can make it as complicated as you want (and there are packages that will build a default structure for you - see also advice #2 below), but for 70% of my needs, this is sufficient (and 100% for everything I teach R with). Any self-contained idea, no matter how small, should be in a separate project.\n\n\n\nA consistent project structure will make your life easier\n\n\nhere() is a simple function that combines strings into paths. The magic bit is that it does so relative to the project location. So you don’t have to remember, or type, that your data is located in /one_folder/another_folder/folder_hell/my_project_folder/data/my_data.csv. If you use projects + here(), it understands where your project is and creates the path relative to it on your hard drive. Like so:\n\nlibrary(here)\n\n# Calling the function with no arguments returns what here understands \n# as the project folder location\nhere()\n\n[1] \"/Users/jarek/Sites/miserable\"\n\n# Calling it with arguments returns path to folders and files relative \n# to the project folder location\nhere(\"data\", \"my_data.csv\")\n\n[1] \"/Users/jarek/Sites/miserable/data/my_data.csv\"\n\n\nIt doesn’t matter if you are on a Linux machine and your collaborator on a Windows, as long as you use the same project structure and here(), wherever your code would refer to files in the project folder, it will work on both machines with no changes.\n\nShort rant about file system\nThe lack of familiarity with the concepts of a filesystem and directory trees is by far the biggest issue for the students who begin working with R. I blame iOS and smartphones to allow people to remain ignorant about the organisation of a computer system, but this issue is particularly compounded by Microsoft’s push to use OneDrive as a main storage space without making it explicit in the user interface.\nStudents tend to download the Rmd/qmd files and open them directly from the downloads folder. This opens RStudio but confuses here(), which shows the downloads folder as the project directory, making all relative links broken. Moreover, RStudio by default opens on the last used project, so its interface shows the “correct” project name and the file system viewer in the bottom right panel shows the “correct” project location on the hard drive.\nThe downloaded file needs to be moved to the appropriate place in the project folder (e.g. code) first, followed by openeing the project itself in RStudio, but this is also tricky for some students, who often struggle to answer the question “where is your project folder?” and locate it with File Explorer (also, “what is File Explorer?”).\nI imagine that the better functionality would be for RStudio to recognise that it is being opened by an “orphan” Rmd/qmd file and ask the user which project does she want it to be opened in (and then move the file to the project folder and open it from there or create a new project at a location specified by the user).\n\n\n\n2. Name things well\nThere is nothing that I can say about naming things that Jenny Bryan and Danielle Navarro haven’t already said much better. Check their presentations, pick one of the suggested approaches to naming and stick to it. Sticking to it is more important than the exact approach that you choose.\n\nProject Structure, a presentation by Danielle Navarro\nNaming, a presentation by Jenny Bryan\n\nA quick question: can you suggest a better way of naming my project folder in the image in #1 above?\n\n\n3. Five or six packages that will make your life much easier\nCheating a little, I also wanted to mention several packages with functions that, in my opinion, really make data wrangling and running statistics (pretty much 90% of what my imaginary target audience wants to do) much easier. Here are the best of:\n\ndatapasta by Miles McBain. It’s an R Studio addin that lets you easily copy-paste basic data structures into R (e.g. vectors and tables), skipping the formatting and importing steps. Here is an animated GIF from the linked website that explains it:\n\n\n\n\nWhat datapasta does. Excellent name, too.\n\n\nOne of my most common uses of it is to create dummy data to test various functions or try to understand what’s going on with my code.\n\njanitor by Sam Firke. Probably the most popular of the basic data wrangling packages, with its blockbuster function clean_names(), which standardises messy column names by substituting spaces, normalising type cases and protecting from having names starting with a number or other forbidden symbol. But it also has a function get_dupes() that identifies duplicated rows/variables in the data and a function tabyl() that prettifies tables, including adding rows with totals or formatting the tables as inputs to statistical tests such as χ2.\nrstatix by Alboukadel Kassambara. This package is useful for two main reasons: a) it provides wrappers around base r statistical tests making them compatible with pipe (including outputting test results as tibbles) and b) it provides function get_summary_stats() that calculates basic and not-so-basic descriptive statistics, also on groupped data. Here is an example:\n\n\nlibrary(tidyverse)\nlibrary(rstatix)\nlibrary(knitr)\n\n# Is there a difference in displacement volume between engines with different number of cylinders?\n# Note that there are more than two groups of cylinder counts (4, 6 and 8)\n\nmtcars %&gt;% \n    t_test(disp ~ cyl) %&gt;% \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.y.\ngroup1\ngroup2\nn1\nn2\nstatistic\ndf\np\np.adj\np.adj.signif\n\n\n\n\ndisp\n4\n6\n11\n7\n-4.422972\n9.224964\n2.0e-03\n2.0e-03\n**\n\n\ndisp\n4\n8\n11\n14\n-12.496797\n17.796601\n0.0e+00\n0.0e+00\n****\n\n\ndisp\n6\n8\n7\n14\n-7.081509\n17.930865\n1.4e-06\n2.7e-06\n****\n\n\n\n\n\nIf your categorical variable contains more than two groups, t_test will automatically perform all pairwise tests between them.\n\n#  Quick summary statistics of engine displacement volumes calculated on data grouped by cylinder count\nmtcars %&gt;% \n    group_by(cyl) %&gt;% \n    get_summary_stats(disp) %&gt;% \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncyl\nvariable\nn\nmin\nmax\nmedian\nq1\nq3\niqr\nmad\nmean\nsd\nse\nci\n\n\n\n\n4\ndisp\n11\n71.1\n146.7\n108.0\n78.85\n120.65\n41.80\n42.995\n105.136\n26.872\n8.102\n18.053\n\n\n6\ndisp\n7\n145.0\n258.0\n167.6\n160.00\n196.30\n36.30\n11.268\n183.314\n41.562\n15.709\n38.439\n\n\n8\ndisp\n14\n275.8\n472.0\n350.5\n301.75\n390.00\n88.25\n73.389\n353.100\n67.771\n18.113\n39.130\n\n\n\n\n\nDo check parameter type = for options of what descriptive statistics you want to include in the output of get_summary_stats().\nThe only (slight) concern about rstatix is its pace of development. Only one issue was patched in the last 1.5 years and at least some of the wrappers do not yet work (e.g. chisq_test() is not pipe-compatible). But other than that rstatix is great.\n\nbroom by David Robinson et al. is another of the “prettifying” packages, this time for statistical model outputs. Essentially, it turns output from lm() (and 100+ other models) into a tidy tabular format. It is also able to add extra columns with residuals and predicted values from the model to the original data. It is now part of the tidymodels approach.\n\n\nlibrary(broom)\n\n# Relationship between engine displacement volume and fuel efficiency\nmtcars %&gt;% \n    ggplot() + aes(x = disp, y = mpg) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = FALSE) + \n    theme_minimal()\n\n\n\n\n\n\n\n# Classic output from lm\nmodel &lt;- lm(mpg ~ disp, data = mtcars)\n\nmodel\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nCoefficients:\n(Intercept)         disp  \n   29.59985     -0.04122  \n\nsummary(model)\n\n\nCall:\nlm(formula = mpg ~ disp, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.8922 -2.2022 -0.9631  1.6272  7.2305 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 29.599855   1.229720  24.070  &lt; 2e-16 ***\ndisp        -0.041215   0.004712  -8.747 9.38e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.251 on 30 degrees of freedom\nMultiple R-squared:  0.7183,    Adjusted R-squared:  0.709 \nF-statistic: 76.51 on 1 and 30 DF,  p-value: 9.38e-10\n\n# And here is the same model presented with broom\nmodel %&gt;% \n    broom::tidy() %&gt;% \n    kable()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n29.5998548\n1.2297195\n24.070411\n0\n\n\ndisp\n-0.0412151\n0.0047118\n-8.747151\n0\n\n\n\n\n# And a tidy table with residuals and fitted values (etc.)\nmodel %&gt;% \n    broom::augment() %&gt;% \n    head() %&gt;% \n    kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.rownames\nmpg\ndisp\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\nMazda RX4\n21.0\n160\n23.00544\n-2.005436\n0.0417535\n3.285085\n0.0086491\n-0.6300752\n\n\nMazda RX4 Wag\n21.0\n160\n23.00544\n-2.005436\n0.0417535\n3.285085\n0.0086491\n-0.6300752\n\n\nDatsun 710\n22.8\n108\n25.14862\n-2.348622\n0.0628778\n3.276208\n0.0186786\n-0.7461691\n\n\nHornet 4 Drive\n21.4\n258\n18.96635\n2.433646\n0.0328126\n3.274958\n0.0098254\n0.7610697\n\n\nHornet Sportabout\n18.7\n360\n14.76241\n3.937588\n0.0663474\n3.219297\n0.0558121\n1.2533143\n\n\nValiant\n18.1\n225\n20.32645\n-2.226453\n0.0313188\n3.280251\n0.0078250\n-0.6957374\n\n\n\n\n\n\nforcats by Hadley Wickham. It is a part of the tidyverse metapackage and is meant to facilitate handling of categorical variables. It is particularly useful for ordering these variables and for grouping them. For example, you can plot only the top three categories in your data (lumping the rest into the “Other” category) with fct_lump() and put the values in decreasing order by median of another variable with fct_reorder().\n\n\ndiamonds %&gt;% \n    sample_frac(0.1) %&gt;% \n    mutate(cut = fct_lump(cut, 3), # Group categories outside of top 3 into \"Other\"\n                 cut = fct_reorder(cut, price, median, .desc = TRUE)) %&gt;% # Reorder categories of diamond cut by median of their price, in decreasing order\n    ggplot(aes(x = cut, y = price)) + \n    geom_boxplot(outliers = FALSE) + \n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n4. Know your interface\nSpend some time on learning the interface of RStudio and force yourself to use its features until they become second nature. In the simplest case, pick a good colour theme in settings, add coloured lines to indicate tabs (and matching colours for brackets), and a good typeface. Uncheck the default options to save history and environment - and make sure you can reproduce your entire analysis from your Rmd/qmd document.\nThen learn the basic keyboard shortcuts (Option-Shift-K shows all shortcuts, for Windows just replace Option with Alt and Command with Windows key):\n\ninsert new chunk (Control-Option-I)\ninsert pipe symbol (Option–)\nrun current line/run current chunk (Control-Enter/Control-Shift-Enter)\nswitch between panes and expand them to full screen (Control-Shift-1 for the source panel, etc.. Press again to expand.)\nmove lines of code up/down (Option-↑ or ↓)\n\nFinally, learn to use these:\n\nmulti-line cursors (Control-Option-↑ or ↓)\nrename-in-scope (Control-Option-Shift-M)\nmulti-file find-and-replace (Shift-Command-F): you need to find stuff first, then toggle Replace switch\n\nGood people at Appsilon have compiled these and many others into a nice gif-torial: RStudio IDE Tips And Tricks - Shortcuts You Must Know Part 1 and Part 2.\n\n\n5. What lies beyond\nFinally, I suggested the following two ideas for further learning and improvement of R workflows:\n\nVersion control. Duh. You should be using it even if you work alone, because it will help you familiarise yourself with it and provide a history of the changes to your code. If you couple it with an online repository (e.g. GitHub, GitLab, Codeberg) it will provide a backup of sorts and, obviously, allow collaborating with others. Happy Git with R remains the best one-stop resource of how to get started with Git and version control through RStudio. \npurrr package and its list-column → nest() → map() approach to iteration. I have become a big fan of it and now almost always shape my data to be compatible with this approach. purrr is a collection of functions that standardise the behaviour or base r *apply() family of functions. They work very well in combination with list-columns, when dataframes (and other objects) are “stored” inside cells of other dataframes. For example, here I split the mtcars dataframe into three nested dataframes, one for each cylinder count, and then apply a custom function (a standard error of the displacement) to each of the nested dataframes, putting its output in another column of the main dataframe. Clear as mud? Well, here it goes:\n\n\n# Step 1: nest your data\nmtcars %&gt;% \n    group_by(cyl) %&gt;% \n    nest() # A list-column with a default name data is created that contains an original data set split by the cyl variable\n\n# A tibble: 3 × 2\n# Groups:   cyl [3]\n    cyl data              \n  &lt;dbl&gt; &lt;list&gt;            \n1     6 &lt;tibble [7 × 10]&gt; \n2     4 &lt;tibble [11 × 10]&gt;\n3     8 &lt;tibble [14 × 10]&gt;\n\n\n\n# Step 2: create a function (if needed) to operate on each nested piece of data\n# A custom function to calculate standard error from the disp column of an input dataframe\nmySE &lt;- function(df){\n        sd(df$disp)/sqrt(length(df$disp)) # I know this is not optimal but bear with me\n}\n\n\n# Step 3: map this function over each nested piece of data\nmtcars %&gt;% \n    group_by(cyl) %&gt;% \n    nest() %&gt;% \n    mutate(disp_se = map(data, mySE))\n\n# A tibble: 3 × 3\n# Groups:   cyl [3]\n    cyl data               disp_se  \n  &lt;dbl&gt; &lt;list&gt;             &lt;list&gt;   \n1     6 &lt;tibble [7 × 10]&gt;  &lt;dbl [1]&gt;\n2     4 &lt;tibble [11 × 10]&gt; &lt;dbl [1]&gt;\n3     8 &lt;tibble [14 × 10]&gt; &lt;dbl [1]&gt;\n\n# By default the output of map() is a list, but there are variants of map() dedicated to particular types of data:\n# for example, if the output is numeric, map_dbl will output the result of your function as a number\nmtcars %&gt;% \n    group_by(cyl) %&gt;% \n    nest() %&gt;% \n    mutate(disp_se = map_dbl(data, mySE))\n\n# A tibble: 3 × 3\n# Groups:   cyl [3]\n    cyl data               disp_se\n  &lt;dbl&gt; &lt;list&gt;               &lt;dbl&gt;\n1     6 &lt;tibble [7 × 10]&gt;    15.7 \n2     4 &lt;tibble [11 × 10]&gt;    8.10\n3     8 &lt;tibble [14 × 10]&gt;   18.1 \n\n\nMap can map your function over every element of the data list-column. With the same approach, you can make a plot of each of these elements and put each plot within a new list-column, thus keeping your data, calculations and visualisations of your data within a single dataframe-like object. I really like this and would recommend anyone to familiarise themselves with it.\n\n# A custom plotting function\nmyPlot &lt;- function(df){\n    df %&gt;% \n        ggplot() + aes(x = disp, y = mpg) + geom_point() + geom_smooth(method = \"lm\", se = FALSE) + theme_minimal()\n}\n\n# The new function is applied over each element of a list-column and output is created in another list-column\nmtcars %&gt;% \n    group_by(cyl) %&gt;% \n    nest() %&gt;% \n    mutate(disp_se = map_dbl(data, mySE),\n                 my_plots = map(data, myPlot))\n\n# A tibble: 3 × 4\n# Groups:   cyl [3]\n    cyl data               disp_se my_plots\n  &lt;dbl&gt; &lt;list&gt;               &lt;dbl&gt; &lt;list&gt;  \n1     6 &lt;tibble [7 × 10]&gt;    15.7  &lt;gg&gt;    \n2     4 &lt;tibble [11 × 10]&gt;    8.10 &lt;gg&gt;    \n3     8 &lt;tibble [14 × 10]&gt;   18.1  &lt;gg&gt;    \n\n\n\n\nGood luck\nAnd that’s it. I hope you will find these tips and resources useful. The original slides from the presentation are available here as a pdf."
  },
  {
    "objectID": "posts/Group-based data analysis project with R/index.html",
    "href": "posts/Group-based data analysis project with R/index.html",
    "title": "Undergraduate group-based data analysis project with R: how we do it",
    "section": "",
    "text": "Everybody should learn to use R…\n…during their undergraduate degree in life sciences.\nIn our case, the students, who attend the classes in 2 groups, in the first 5-6 week are individually learning the basics of data analysis with R. Then the students are split into 5-6-person teams to complete a group-based project, which is an open-ended analysis of a complex dataset. We only work in a Windows-based environment and we do not use version control.\nFor more details about what we do in these clasess, see my other post.\nThe teams’ analyses are marked based on na R Notebook file from which we could reproduce their analyses.\nTo the vast majority of the students, this is their first contact with programming of any sort, and the first contact with concepts of file system and paths (speaking from experience, it looks like these concepts are black magic to almost anyone born after 1990). This excludes any chance of using, for example, version control on their code submissions, which would allow direct quantification of individual students’ contributions to the codebase. In addition, we do not expect every student in the team to contribute equally to all elements of the assignment; some division of labour will occur, either naturally or because some students would avoid doing coding or prefer other elements of the project.\nBut the system described below is agnostic to the topic, number of groups or teams or peer-marking criteria.\nWe have two independent groups of students and each group is split into several teams of 4-6 students. The peer marking system has five criteria, based on which each student anonymously marks other students in their team. The peer-marking is run twice in a term, once three weeks after the beginning of the group work and the second time in the final week of the class.\n\n\nMarking criteria\n\n\n\n\n\n\nMarking criteria\n\n\n\n\nAbility to provide direction for the group activities (leadership)\n\n\nInvolvement in the execution of the project work (developing R code)\n\n\nInvolvement in the presentation of group work\n\n\nAbility to suggest solutions and other approaches to group or work challenges (creativity)\n\n\nAbility to work well with and support other members of the group\n\n\n\n\nTable with peer-marking criteria\n\n\n\n\n\n\nPeer mark\nGuidance\n\n\n\n\n0\nStudent did not contribute at all; was missing most of the time; did not complete assigned tasks; team’s results would not change had this person not been a member of the team\n\n\n1\nStudent contributed only minimally; attendance and task completion was low; team’s results would change only slightly had this person not been a member of the team\n\n\n2\nAt least one of the elements (student contributions/attendance/task completion), including the contributions, was adequate\n\n\n3\nAt least two of the elements (student contributions/attendance/task completion), including the contributions, were good\n\n\n4\nStudent made substantial contributions to the team’s results and maintained very good attendance and task completion\n\n\n5\nStudent made significant and substantial contributions; the team’s results would be noticeably worse without them; all other responsibilities were completed (i.e. attended all meetings, completed all tasks)"
  },
  {
    "objectID": "posts/Groups and peer marking system in R part 1/index.html",
    "href": "posts/Groups and peer marking system in R part 1/index.html",
    "title": "Group work and peer-marking system with R: part 1",
    "section": "",
    "text": "Some background\nHere is an imaginary scenario: you are running a class where you have to split students into teams, in which they are to complete a project of some sort. Further imagine that you would like to track the level of contribution of each member of a team to the final project mark and potentially be able to detect conflicts early. Also, you happen to know R…\n\n\nThe system\nThe system comprises of three elements:\n\ndividing students into teams of a given size; we split students randomly into teams and only perform a manual check for gender balance of each team;\ngenerating Excel peer-marking forms that will be distributed to each student;\ncollecting the forms and calculating an average mark for each criterion for each student, based on their team-mates marks; this mark will be ultimately released to each student.\n\nStudents don’t mark themselves in this system (although it is easy to extend it to self-mark).\n\n\nLet’s code\nFinally!\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\nhere() starts at /Users/jarek/Sites/miserable-quarto\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(readxl)\nlibrary(writexl)\n\n\nAssigning students to teams\nFirstly, we load the list of students and their IDs, alongside information to which group they are assigned (teams must be created within each group). Depending on how your list of students is generated, some tidying up may be required here. In this example, I have two groups of students (I am using the names of characters of the Grishaverse novels by Leigh Bardugo) and the file is already tidy.\n\n# List of groups and teams is provided in an Excel file\ngroups &lt;- read_xlsx(here(\"posts\", \"Groups and peer marking system in R part 1\", \"groups_example.xlsx\"))\n\ngroups\n\n# A tibble: 23 × 3\n   student_name     student_number group \n   &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt; \n 1 Alina Starkov             11110 group1\n 2 Nikolai Lantsov           22220 group1\n 3 Zoya Nazyalensky          33330 group1\n 4 Malyen Oretsev            44440 group1\n 5 Genya Safin               55550 group1\n 6 David Kostyk              66660 group1\n 7 Adrik Zhabin              77770 group1\n 8 Hanne Brum                88880 group1\n 9 Isaak Andreyev            99990 group1\n10 Mayu Kir-Kaat            121212 group1\n# ℹ 13 more rows\n\n\nWe also need another file with the names for the teams (list of cities and places in the Grishaverse), or we can manually create a character vector for this purpose.\n\n# Teams' names are also provided in an Excel file, but any vector with names will do\nteams_names &lt;- read_xlsx(here(\"posts\", \"Groups and peer marking system in R part 1\", \"teams_names_example.xlsx\")) %&gt;% pull(teams_names) %&gt;% sample()\n\nteams_names\n\n[1] \"Shu Han\"     \"Fjerda\"      \"Ketterdam\"   \"Novyi Zem\"   \"Os Alta\"    \n[6] \"Ice Court\"   \"Ravka\"       \"Shadow Fold\"\n\n\nBefore the main assignment is run, we need to decide on how many students should be in each team. Counting how many students are there in each group should help with that, and setting up a desired number of students per team will do the rest. We use floor() to round down the number of teams per group, so the actual number of students in each team can be higher than the desired number.\n\n# How many teams can we fit in each group, assuming students_per_team in each team\n# Note this number of students per team will be approximate, some groups may end up being larger\nstudents_per_team = 4\n\ngroups %&gt;% \n    count(group)\n\n# A tibble: 2 × 2\n  group      n\n  &lt;chr&gt;  &lt;int&gt;\n1 group1    10\n2 group2    13\n\ngroups %&gt;% \n    group_by(group) %&gt;% \n    summarise(teams_per_group = floor(n()/students_per_team))\n\n# A tibble: 2 × 2\n  group  teams_per_group\n  &lt;chr&gt;            &lt;dbl&gt;\n1 group1               2\n2 group2               3\n\n\nI am a fan of the purrr’s package nest-map way of looping a function over multiple groups and have learned to shape the data in the way compatible with this workflow. Here, the challenge is that our arranging students into teams has to be done within each group, and the process has to be generalisable to any number of groups and any number of students per group.\nThis is how I go about it:\n\nfirst, I split the data by group and for each group, I calculate the number of teams that I want to create given a desired number of students per team;\nthen, I randomise order of students in each group and assign them to the specified number of teams;\nfinally, I assign a randomly chosen name for each team across all groups so that each team name is unique for the whole class.\n\nThere probably exists a much simpler way of doing this (let me know!), but it works here.\n\n# Create a function to randomise order of students in each group and then split them into defined number of teams\nsplit2Teams &lt;- function(df, no_of_teams) {\n    df %&gt;% \n        slice_sample(n = nrow(.)) %&gt;% \n        split(., 1:no_of_teams)\n}\n\n# Split students into groups and for each group: calculate number of teams, run the above function to arrange them randomly into teams and assign a unique team name.\n# Note: every time you run this piece of code, team assignment will change!\nteams_ready &lt;- groups %&gt;% \n    nest(data = -group) %&gt;% \n    mutate(no_of_teams = map_dbl(data, ~floor(nrow(.)/students_per_team))) %&gt;% \n    mutate(teams = map2(data, no_of_teams, split2Teams)) %&gt;% \n    unnest(teams) %&gt;% \n    mutate(teams = map2(teams, sample(teams_names[1:length(teams)]), ~mutate(.x, team_name = .y))) %&gt;% # Assign a random team name to each team\n    select(-c(data, no_of_teams)) %&gt;% \n    unnest(teams) %&gt;% \n    relocate(team_name, .after = student_number)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `teams = map2(data, no_of_teams, split2Teams)`.\nCaused by warning in `split.default()`:\n! data length is not a multiple of split variable\n\nteams_ready\n\n# A tibble: 23 × 4\n   group  student_name     student_number team_name\n   &lt;chr&gt;  &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt;    \n 1 group1 Malyen Oretsev            44440 Os Alta  \n 2 group1 Mayu Kir-Kaat            121212 Os Alta  \n 3 group1 Alina Starkov             11110 Os Alta  \n 4 group1 Nikolai Lantsov           22220 Os Alta  \n 5 group1 Adrik Zhabin              77770 Os Alta  \n 6 group1 Zoya Nazyalensky          33330 Fjerda   \n 7 group1 Genya Safin               55550 Fjerda   \n 8 group1 David Kostyk              66660 Fjerda   \n 9 group1 Hanne Brum                88880 Fjerda   \n10 group1 Isaak Andreyev            99990 Fjerda   \n# ℹ 13 more rows\n\n\nLet’s save the list with ready-made teams to an Excel file, ready to be published for the students. After the file is created, I manually inspect it to make sure there is roughly the same proportion of males and females in each team and make adjustments to rearrange teams if necessary.\n\nwrite_xlsx(teams_ready, here(\"posts\", \"Groups and peer marking system in R part 1\", paste(\"teams_ready\", Sys.Date(), \".xlsx\", sep = \"_\")))\n\n\n\nGenerating peer-marking forms\nThis was the easy bit. Now, we have to generate a set of files, one for each student, where each file contains the marking criteria and a set of columns for all the students in a team apart from the student to whom the file is addressed.\n\n# A vector with all teams' names\ntnames &lt;- sort(unique(teams_ready$team_name))\n\n# A list where each element, named after a team name, is a list of students in that team\ntlist &lt;- map(tnames, ~teams_ready %&gt;% filter(team_name == .x) %&gt;% pull(student_name)) %&gt;% set_names(tnames)\n\n# map(tnames, ~teams_ready %&gt;% filter(team_name == .x) %&gt;% select(student_name))\n\n# A list where each element, named after a team name, combines elements \"question\" and \"team_name\" with the list of students in that team\nbiglist &lt;- map(tlist, ~c(list(question = NA_character_, team_name = NA_character_), Map(function(x) NA_character_, .x)))\n\n\n# https://stackoverflow.com/questions/30150977/r-combine-list-of-data-frames-into-single-data-frame-add-column-with-list-inde\n# split2Teams2 &lt;- function(df, students_per_team){\n#   number_of_teams = floor(nrow(df)/students_per_team)\n#   df %&gt;% split(., sample(sample(teams_names, students_per_team, replace = FALSE), number_of_teams)) %&gt;% \n#       bind_rows(., .id = \"team_name\")\n#   }\n# \n# groups %&gt;% \n#   nest(data = -group) %&gt;% \n#   mutate(teams = map2(data, 4, splitTeams2)) %&gt;% \n#   select(-data) %&gt;% \n#   unnest(teams)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "miserable uncertainty",
    "section": "",
    "text": "R, with a little help from a few friends\n\n\n\n\n\n\nteaching and learning\n\n\nR\n\n\nnorthernBUG\n\n\n\n\n\n\n\n\n\nAug 22, 2024\n\n\nJarek Bryk\n\n\n\n\n\n\n\n\n\n\n\n\nGroup work and peer-marking system with R: part 2\n\n\n\n\n\n\nR\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nNov 21, 2022\n\n\nJarek Bryk\n\n\n\n\n\n\n\n\n\n\n\n\nGroup work and peer-marking system with R: part 1\n\n\n\n\n\n\nR\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nOct 16, 2022\n\n\nJarek Bryk\n\n\n\n\n\n\n\n\n\n\n\n\nUndergraduate group-based data analysis project with R: how we do it\n\n\n\n\n\n\nteaching and learning\n\n\nR\n\n\n\n\n\n\n\n\n\nSep 18, 2022\n\n\nJarek Bryk\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/R with a little help from a few friends/index.html#good-luck",
    "href": "posts/R with a little help from a few friends/index.html#good-luck",
    "title": "R, with a little help from a few friends",
    "section": "Good luck",
    "text": "Good luck\nAnd that’s it. I hope you will find these tips and resources useful. The original slides from the presentation are available here as a pdf."
  }
]